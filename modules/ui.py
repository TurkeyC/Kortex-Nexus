import streamlit as st
from typing import List, Dict, Any, Callable, Optional


def setup_page(title: str, description: str, theme: str = "light"):
    """è®¾ç½®é¡µé¢åŸºæœ¬é…ç½® - å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ªStreamlitå‘½ä»¤"""
    # è¿™ä¸ªå¿…é¡»æ˜¯è„šæœ¬ä¸­æ‰§è¡Œçš„ç¬¬ä¸€ä¸ªstå‘½ä»¤
    st.set_page_config(
        page_title=title,
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded",
    )


def apply_custom_styles(theme: str = "light"):
    """åº”ç”¨è‡ªå®šä¹‰æ ·å¼ - åœ¨set_page_configä¹‹åè°ƒç”¨"""
    # è®¾ç½®ä¸»é¢˜
    if theme == "dark":
        st.markdown("""
        <style>
        :root {
            --main-bg-color: #0e1117;
            --sidebar-bg-color: #262730;
            --text-color: #ffffff;
        }
        </style>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <style>
        :root {
            --main-bg-color: #ffffff;
            --sidebar-bg-color: #f0f2f6;
            --text-color: #31333f;
        }
        </style>
        """, unsafe_allow_html=True)

    # è‡ªå®šä¹‰CSSä»¥æé«˜ç•Œé¢ç¾è§‚åº¦
    st.markdown("""
    <style>
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.8rem;
        margin-bottom: 1rem;
        display: flex;
    }
    .chat-message.user {
        background-color: #f0f2f6;
    }
    .chat-message.bot {
        background-color: #e3f2fd;
    }
    .chat-message .avatar {
        width: 20%;
    }
    .chat-message .avatar img {
        max-width: 78px;
        max-height: 78px;
        border-radius: 50%;
        object-fit: cover;
    }
    .chat-message .message {
        width: 80%;
        padding: 0 1.5rem;
    }

    /* å®šåˆ¶æ»šåŠ¨æ¡ */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }
    ::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 5px;
    }
    ::-webkit-scrollbar-thumb {
        background: #888;
        border-radius: 5px;
    }
    ::-webkit-scrollbar-thumb:hover {
        background: #555;
    }
    </style>
    """, unsafe_allow_html=True)


def display_header(title: str, description: str):
    """æ˜¾ç¤ºæ ‡é¢˜å’Œæè¿°"""
    st.title(title)
    st.markdown(description)


def render_sidebar(
        available_models: List[str],
        on_model_change: Callable[[str], None],
        on_feature_mode_change: Optional[Callable[[str], None]] = None,
        available_features: Optional[List[str]] = None,
        advanced_features_enabled: Optional[Dict[str, bool]] = None
):
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.header("è®¾ç½®")

        # æ¨¡å‹é€‰æ‹©
        model_display_names = {
            "ollama": "Ollama (æœ¬åœ°éƒ¨ç½²)",
            "moonshot": "Moonshot AI (äº‘API)",
            "lmstudio": "LM Studio (æœ¬åœ°éƒ¨ç½²)",
            "deepseek": "DeepSeek (äº‘API)"
        }

        # ä¿®æ”¹ä¸ºä¼˜å…ˆé€‰æ‹©lmstudio
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=available_models,
            format_func=lambda x: model_display_names.get(x, x),
            index=available_models.index("lmstudio") if "lmstudio" in available_models else 0
        )
        on_model_change(selected_model)

        # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤ºé¢å¤–é€‰é¡¹
        if selected_model == "ollama":
            # å¯¹äºOllamaï¼Œæ˜¾ç¤ºæ¨¡å‹åç§°é€‰é¡¹
            ollama_models = ["llama3", "mistral", "gemma", "phi3", "llama3:8b", "llama3:70b"]
            ollama_selected = st.selectbox(
                "Ollamaæ¨¡å‹",
                options=ollama_models,
                index=0
            )
            st.session_state.ollama_model_name = ollama_selected

        elif selected_model == "moonshot":
            # å¯¹äºMoonshotï¼Œæ˜¾ç¤ºä¸Šä¸‹æ–‡çª—å£é€‰é¡¹
            moonshot_models = ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"]
            moonshot_selected = st.selectbox(
                "Moonshotæ¨¡å‹",
                options=moonshot_models,
                index=0
            )
            st.session_state.moonshot_model_name = moonshot_selected

            # APIå¯†é’¥è¾“å…¥
            moonshot_api_key = st.text_input(
                "Moonshot APIå¯†é’¥",
                value=st.session_state.get("moonshot_api_key", ""),
                type="password"
            )
            st.session_state.moonshot_api_key = moonshot_api_key

        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = st.text_area(
            "ç³»ç»Ÿæç¤ºè¯",
            value="ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†ä¸°å¯Œçš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚",
            height=100
        )

        # æ¸©åº¦å‚æ•°
        temperature = st.slider(
            "æ¸©åº¦",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            step=0.1,
            help="è¾ƒé«˜çš„å€¼ä¼šä½¿è¾“å‡ºæ›´åŠ éšæœºï¼Œè¾ƒä½çš„å€¼ä¼šä½¿è¾“å‡ºæ›´åŠ ç¡®å®šã€‚"
        )

        # çŸ¥è¯†åº“ç®¡ç†
        with st.expander("çŸ¥è¯†åº“ç®¡ç†", expanded=False):
            # ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“",
                type=["md", "txt", "pdf"],
                help="æ”¯æŒMarkdownã€txtå’ŒPDFæ ¼å¼"
            )

            col1, col2 = st.columns(2)
            with col1:
                if st.button("åˆ·æ–°çŸ¥è¯†åº“", use_container_width=True):
                    with st.spinner("åˆ·æ–°ä¸­..."):
                        st.session_state.knowledge_base.load_knowledge_base()
                    st.success("çŸ¥è¯†åº“å·²æ›´æ–°")

            with col2:
                if uploaded_file:
                    if st.button("å¤„ç†ä¸Šä¼ æ–‡ä»¶", use_container_width=True):
                        save_path = str(st.session_state.knowledge_base.knowledge_dir / uploaded_file.name)
                        with open(save_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        with st.spinner("å¤„ç†ä¸­..."):
                            st.session_state.knowledge_base.load_knowledge_base()
                        st.success(f"å·²ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶ï¼š{uploaded_file.name}")

        # é¢„å¼€å‘åŠŸèƒ½é€‰æ‹©ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if available_features and on_feature_mode_change:
            st.header("åŠŸèƒ½æ¨¡å¼")

            # åˆ›å»ºå‹å¥½çš„æ˜¾ç¤ºåç§°æ˜ å°„
            feature_display_names = {
                "standard": "æ ‡å‡†æ¨¡å¼",
                "swarms": "Swarms - å¤šæ™ºèƒ½ä½“åä½œ",
                "storm": "Storm - ä¸“å®¶åä½œç³»ç»Ÿ",
                "consciousness": "Consciousness Flow - åˆ›æ–°æ€è€ƒ",
                "hook": "Hook - å¼•å¯¼å¼å¯¹è¯"
            }

            # è¿‡æ»¤å¯ç”¨åŠŸèƒ½
            active_features = ["standard"]  # æ ‡å‡†æ¨¡å¼å§‹ç»ˆå¯ç”¨
            if advanced_features_enabled:
                for feature in available_features:
                    if feature != "standard" and advanced_features_enabled.get(f"enable_{feature}", False):
                        active_features.append(feature)

            # æ˜¾ç¤ºåŠŸèƒ½é€‰æ‹©å™¨
            selected_feature = st.selectbox(
                "é€‰æ‹©åŠŸèƒ½æ¨¡å¼",
                options=active_features,
                format_func=lambda x: feature_display_names.get(x, x),
                index=0
            )

            # æ›´æ–°åŠŸèƒ½æ¨¡å¼
            on_feature_mode_change(selected_feature)

            # æ˜¾ç¤ºåŠŸèƒ½è¯´æ˜
            feature_descriptions = {
                "standard": "æ ‡å‡†å¯¹è¯æ¨¡å¼ï¼Œä½¿ç”¨é€‰å®šçš„å¤§æ¨¡å‹ç›´æ¥å›ç­”é—®é¢˜ã€‚",
                "swarms": "å¤šæ™ºèƒ½ä½“åä½œæ¨¡å¼ï¼Œç”±å¤šä¸ªä¸“ä¸šé¢†åŸŸæ¨¡å‹ååŒè§£å†³é—®é¢˜ã€‚",
                "storm": "ä¸“å®¶åä½œç³»ç»Ÿï¼Œåˆ†æé—®é¢˜å¹¶è°ƒç”¨ä¸“ä¸šæ¨¡å‹è¿›è¡Œå¤´è„‘é£æš´ã€‚",
                "consciousness": "åˆ›æ–°æ€è€ƒæ¨¡å¼ï¼Œç”Ÿæˆæ— ç›®çš„æ€è€ƒå¹¶ç­›é€‰æœ‰ä»·å€¼å†…å®¹ã€‚",
                "hook": "å¼•å¯¼å¼å¯¹è¯ï¼Œå¤šæ¨¡å‹åˆ†æé—®é¢˜ï¼Œé€æ­¥å¼•å¯¼ç”¨æˆ·è‡³ç»“è®ºã€‚"
            }

            st.info(feature_descriptions.get(selected_feature, ""))

        # ç‰ˆæœ¬ä¿¡æ¯
        st.markdown("---")
        st.markdown("**V 0.1**")

    # æ ¹æ®é€‰å®šçš„æ¨¡å‹æ›´æ–°é…ç½®
    if selected_model == "ollama" and hasattr(st.session_state, 'ollama_model_name'):
        import config
        config.MODEL_CONFIG["ollama"]["model_name"] = st.session_state.ollama_model_name

    elif selected_model == "moonshot" and hasattr(st.session_state, 'moonshot_model_name'):
        import config
        import os
        config.MODEL_CONFIG["moonshot"]["model_name"] = st.session_state.moonshot_model_name
        if hasattr(st.session_state, 'moonshot_api_key') and st.session_state.moonshot_api_key:
            config.MODEL_CONFIG["moonshot"]["api_key"] = st.session_state.moonshot_api_key
            os.environ["MOONSHOT_API_KEY"] = st.session_state.moonshot_api_key

    return {
        "model": selected_model,
        "system_prompt": system_prompt,
        "temperature": temperature,
        "feature_mode": selected_feature if 'selected_feature' in locals() else "standard"
    }


def render_chat_area(on_send: Callable[[str], None]):
    """æ¸²æŸ“èŠå¤©åŒºåŸŸ"""
    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)

        # å¤„ç†å›å¤
        on_send(prompt)


def display_assistant_response(response: str):
    """æ˜¾ç¤ºåŠ©æ‰‹å›å¤"""
    # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
    st.session_state.messages.append({"role": "assistant", "content": response})

    # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯
    with st.chat_message("assistant"):
        st.markdown(response)
